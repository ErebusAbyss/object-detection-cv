{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Конвертація завершена! TXT в data/labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Pathes\n",
    "data_root = 'VOC_dataset/VOCdevkit'\n",
    "years = ['VOC2007', 'VOC2012']\n",
    "output_dir = 'data/original_labels'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Class mapping\n",
    "classes = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "           'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "class_to_id = {cls: i for i, cls in enumerate(classes)}\n",
    "\n",
    "for year in years:\n",
    "    annotations_dir = os.path.join(data_root, year, 'Annotations')\n",
    "    for xml_file in os.listdir(annotations_dir):\n",
    "        if not xml_file.endswith('.xml'):\n",
    "            continue\n",
    "        xml_path = os.path.join(annotations_dir, xml_file)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        img_filename = root.find('filename').text\n",
    "        width = int(root.find('size/width').text)\n",
    "        height = int(root.find('size/height').text)\n",
    "        \n",
    "        txt_lines = []\n",
    "        for obj in root.iter('object'):\n",
    "            cls_name = obj.find('name').text.lower()\n",
    "            if cls_name not in class_to_id:\n",
    "                continue\n",
    "            cls_id = class_to_id[cls_name]\n",
    "            \n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = float(bndbox.find('xmin').text)\n",
    "            ymin = float(bndbox.find('ymin').text)\n",
    "            xmax = float(bndbox.find('xmax').text)\n",
    "            ymax = float(bndbox.find('ymax').text)\n",
    "            \n",
    "            # Normalization for YOLO\n",
    "            x_center = (xmin + xmax) / 2 / width\n",
    "            y_center = (ymin + ymax) / 2 / height\n",
    "            w = (xmax - xmin) / width\n",
    "            h = (ymax - ymin) / height\n",
    "            \n",
    "            txt_lines.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\")\n",
    "        \n",
    "        # Saving TXT (with the same name as XML, but in output_dir)\n",
    "        txt_path = os.path.join(output_dir, xml_file.replace('.xml', '.txt'))\n",
    "        if txt_lines:\n",
    "            with open(txt_path, 'w') as f:\n",
    "                f.write('\\n'.join(txt_lines)) \n",
    "\n",
    "print(\"Conversion completed! TXT в data/original_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c220851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom спліти створено і файли скопійовано в data/custom_data!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def create_custom_splits_and_copy(years, base_dir, output_base='data/custom_data'):\n",
    "    # Create folders for images and labels in custom_data\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        os.makedirs(os.path.join(output_base, 'images', split), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_base, 'labels', split), exist_ok=True)\n",
    "    \n",
    "    # Dictionaries for splits (train based on trainval for more data)\n",
    "    splits = {\n",
    "        'train': 'trainval',\n",
    "        'val': 'val',\n",
    "        'test': 'test'\n",
    "    }\n",
    "    \n",
    "    # Collect unique IDs for each split\n",
    "    all_splits = {split: set() for split in splits}\n",
    "    \n",
    "    for year in years:\n",
    "        imagesets_dir = os.path.join(base_dir, year, 'ImageSets/Main')\n",
    "        jpeg_dir = os.path.join(base_dir, year, 'JPEGImages')\n",
    "        \n",
    "        for split, original_txt in splits.items():\n",
    "            txt_path = os.path.join(imagesets_dir, f'{original_txt}.txt')\n",
    "            if os.path.exists(txt_path):\n",
    "                with open(txt_path, 'r') as f:\n",
    "                    ids = [line.strip() for line in f if line.strip()]\n",
    "                all_splits[split].update(ids)\n",
    "    \n",
    "    # Copy files with prefixes for uniqueness\n",
    "    for split in all_splits:\n",
    "        for img_id in all_splits[split]:\n",
    "            for year in years:\n",
    "                original_jpg = os.path.join(base_dir, year, 'JPEGImages', f'{img_id}.jpg')\n",
    "                original_txt = os.path.join('data/original_labels', f'{img_id}.txt')\n",
    "                \n",
    "                if os.path.exists(original_jpg) and os.path.exists(original_txt):\n",
    "                    new_id = f'{year}_{img_id}'  # Year prefix for uniqueness\n",
    "                    new_jpg = os.path.join(output_base, 'images', split, f'{new_id}.jpg')\n",
    "                    new_txt = os.path.join(output_base, 'labels', split, f'{new_id}.txt')\n",
    "                    \n",
    "                    shutil.copy(original_jpg, new_jpg)\n",
    "                    shutil.copy(original_txt, new_txt)\n",
    "                    break\n",
    "    \n",
    "    # Creating custom TXT with new IDs (for .yaml)\n",
    "    for split in all_splits:\n",
    "        custom_txt_path = os.path.join(output_base, f'custom_{split}.txt')\n",
    "        with open(custom_txt_path, 'w') as f:\n",
    "            for img_id in sorted(all_splits[split]):\n",
    "                for year in years:\n",
    "                    if os.path.exists(os.path.join(base_dir, year, 'JPEGImages', f'{img_id}.jpg')):\n",
    "                        f.write(f'{year}_{img_id}\\n')\n",
    "                        break\n",
    "    \n",
    "    print(\"Custom splits created and files copied to data/custom_data!\")\n",
    "\n",
    "create_custom_splits_and_copy(['VOC2007', 'VOC2012'], 'VOC_dataset/VOCdevkit', 'data/custom_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Object Detection (venv)",
   "language": "python",
   "name": "object_detection_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
